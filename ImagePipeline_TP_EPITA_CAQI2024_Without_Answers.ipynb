{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-JQO502qdCb"
   },
   "source": [
    "# TP: Introduction to an Image Processing Pipeline\n",
    "\n",
    "### Name: **ISMAILI Adam**\n",
    "\n",
    "The objective of this TP is to play with a simple pipeline to \"develop\" a raw image into an image in JPEG format.\n",
    "\n",
    "We will go through the following steps:\n",
    "- Import and observe a raw image\n",
    "- Linearization and exposure\n",
    "- Demosaicing\n",
    "- White balance\n",
    "- Color Rendering\n",
    "- Gamma compression\n",
    "- Common image enhancements: saturation, contrast, sharpening\n",
    "\n",
    "The purpose of the TP is not for you to implement image processing but just to observe the effect of each steps and understand what is does.\n",
    "Code is provided for each step, so that you can read and understand the concept of each processing at the pixel level.\n",
    "\n",
    "Answer the questions below and then export the notebook with the answers using the menu option File->Download .ipynb. **[Then submit your solution here!](\n",
    "https://docs.google.com/forms/d/e/1FAIpQLSeXRzNII8MCQ6k0HJ15ilf7JQjMYVJEaM7xuvXRoqMg_BDzxQ/viewform\n",
    ")**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ikL-Nyvh1idf"
   },
   "source": [
    "Install necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OgVNYxLCil_L",
    "outputId": "d85328d7-cb1a-42fb-c871-16beae8fcf7a"
   },
   "outputs": [],
   "source": [
    "!pip install rawpy\n",
    "!pip install imageio\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gD7fQ-Rvm3Q"
   },
   "source": [
    "Import necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3ffiwOahaSj"
   },
   "outputs": [],
   "source": [
    "import io, requests, rawpy\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mLc-saaihBT",
    "outputId": "6a360265-eea1-49ae-c63b-ccc51d82e32c"
   },
   "outputs": [],
   "source": [
    "# The following lines install the necessary packages in the colab environment\n",
    "try:\n",
    "    from google.colab import files\n",
    "    !pip install -q hdf5storage\n",
    "\n",
    "    !rm -fr IspPipeline\n",
    "    !git clone -b dataonly --single-branch --quiet https://github.com/DXOMARK-OCTO/IspPipeline\n",
    "    !cp -r IspPipeline/* .\n",
    "\n",
    "except ImportError:\n",
    "    # %matplotlib notebook\n",
    "    pass\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper function for displaying images\n",
    "def imshow(im, **kwargs):\n",
    "  im = im / im.max()\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.imshow(im, **kwargs)\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umXJ3YjviYk7"
   },
   "source": [
    "# Import a Raw Image\n",
    "\n",
    "In this section we will import a raw image from a DNG file.\n",
    "DNG is a universal file format developped by Adobe for raw images.\n",
    "It contains the raw data from the sensor as well as some metadata useful to transform the raw data to a viewable image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvQB-Jv2i7mh"
   },
   "outputs": [],
   "source": [
    "raw = rawpy.imread(\"./SonyA7S3/ISO100.dng\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkOqIhKMvwR-"
   },
   "source": [
    "A raw image contains raw data (pixels in bayer pattern) but also metadata to \"develop\" the image and a thumbnail.\n",
    "Let's start by looking at the thumbnail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "lQd8OscNsIm4",
    "outputId": "3479fecc-ea4e-4131-8eca-35dd9a8cdc6c"
   },
   "outputs": [],
   "source": [
    "thumb_bytes = raw.extract_thumb().data\n",
    "thumb_img = imageio.imread(thumb_bytes)\n",
    "imshow(thumb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJr7IkIvo11c"
   },
   "source": [
    "Now let's extract the raw data and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "id": "2lvqnNpOsXj-",
    "outputId": "3d635638-4193-4f05-d9d4-738c8fa1ab91"
   },
   "outputs": [],
   "source": [
    "rh, rw = raw.sizes.raw_height, raw.sizes.raw_width\n",
    "print(f\"Raw image height and width: {rh}, {rw}\")\n",
    "img_raw = raw.raw_image.copy().astype(float)\n",
    "print(f\"Raw image min and max values: {img_raw.min()}, {img_raw.max()}\")\n",
    "print(f\"Raw image average value: {img_raw.mean()}\")\n",
    "imshow(img_raw, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gw2U6AoDzUF0"
   },
   "source": [
    "Let's maginify the image to see the Bayer color filter array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "Gn8f8k1_qYRA",
    "outputId": "ea77e8fe-72ac-4cae-ba15-07da0f172ab5"
   },
   "outputs": [],
   "source": [
    "imshow(img_raw[1842:1872, 1778:1820], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VrmXUEEk2GGS"
   },
   "source": [
    "Let's explore some of the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nJSIw3sW2LyO",
    "outputId": "c1079520-436c-448e-c876-45f7ba576d1a"
   },
   "outputs": [],
   "source": [
    "bayer_pattern = raw.raw_pattern\n",
    "print(f\"Bayer pattern: {bayer_pattern}\")\n",
    "blc = raw.black_level_per_channel\n",
    "print(f\"Black level: {blc}\")\n",
    "wl  = raw.white_level\n",
    "print(f\"White level: {wl}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJQv3wHjQX5R"
   },
   "source": [
    "The encoding of the Bayer pattern is as follows:\n",
    "0 = Red, 1 = GreenTR for TopRight, 2 = Blue, 3 = GreenBL for Bottom Left.\n",
    "\n",
    "This means that the pixel at the top left of the sensor in the Sony A7S3 is red, like this:\n",
    "\n",
    "![Pattern.jpg](data:image/jpeg;base64,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)\n",
    "\n",
    "Without loss of generality, we suppose this Bayer configuration for the rest of this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsxrYNg933Np"
   },
   "source": [
    "# Linearization\n",
    "\n",
    "Black level is an analog offset applied on the output of the photo diode. It allows to keep a normal distribution for the readout noise. For now, we will remove this offset to obtain a linear image, i.e. an image where gray levels are proportional to light intensity in each channel.\n",
    "\n",
    "In the general case, the black level can be different for each channel. But for the Sony A7S3, as we have just observed, the value is the same for all channels.\n",
    "\n",
    "Also, we find it convenient to normalize the pixel values such that 1.0 corresponds to pure white."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhbLzq8V4b_U",
    "outputId": "b5e2fba9-28db-4734-d391-b50ee838310f"
   },
   "outputs": [],
   "source": [
    "bl = blc[0]  # same for all channels\n",
    "img_lin = (img_raw - bl) / (wl - bl)\n",
    "print(f\"Min and max values after linearization: {img_lin.min()}, {img_lin.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SBYFSOcW6Jj8"
   },
   "source": [
    "Observe that we have negative values. We will come back on those when discussing noise. For now we just get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXpg5eNO6X3E",
    "outputId": "ee3c9fd0-0cf8-43d1-d092-7950a26c0759"
   },
   "outputs": [],
   "source": [
    "img_lin[img_lin < 0] = 0\n",
    "print(f\"Min and max values after linearization and clamp: {img_lin.min()}, {img_lin.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rmjPk4UYgvf"
   },
   "source": [
    "# Exposure\n",
    "\n",
    "In this section we will adjust the target exposure with a global gain on the raw image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzAuKkZu-10V"
   },
   "source": [
    "As we have explained in the first lecture, exposure is adjusted right in the sensor, via shutter and ISO speed, even before the image is captured. In order to keep headroom for color and highlight manipulation many cameras intentionally underexpose the images. The Sony A7S3 that we use for this exercise underexposes by approximately 2 \"stops\", i.e. by a factor of 4. We start by applying this coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lzj9DLgICloH"
   },
   "outputs": [],
   "source": [
    "img_expo = (4 * img_lin).clip(0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrF3GnO-VbLc"
   },
   "source": [
    "# Demosaicing\n",
    "\n",
    "In this section we will apply demosaicing to the image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eX1JHNiElnfr"
   },
   "source": [
    "## Assign Colors to Pixels\n",
    "\n",
    "To get started, we assign the observed pixel values to their corresponding channels, based on their position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "id": "PXQcTwPCH1NP",
    "outputId": "07907d0d-bdde-44fc-fad8-faffdb25dd5d"
   },
   "outputs": [],
   "source": [
    "def isp_split_colors(img_in) -> np.ndarray:\n",
    "  h, w = img_in.shape\n",
    "  img_out = np.zeros((h, w, 3))\n",
    "  # Red\n",
    "  img_out[0::2, 0::2, 0] = img_in[0::2, 0::2]\n",
    "  # Green\n",
    "  img_out[1::2, 0::2, 1] = img_in[1::2, 0::2]\n",
    "  img_out[0::2, 1::2, 1] = img_in[0::2, 1::2]\n",
    "  # Blue\n",
    "  img_out[1::2, 1::2, 2] = img_in[1::2, 1::2]\n",
    "  return img_out\n",
    "\n",
    "img_split = isp_split_colors(img_expo)\n",
    "imshow(img_split[1842:1872, 1778:1820])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tSLfpUl_8Un3"
   },
   "source": [
    "## Bilinear Interpolation\n",
    "\n",
    "Next we apply naive bilinear interpolation as best guess for all the missing pixels. To interpolate missing G values on red and blue pixels, we use the four closest neighbors. To interpolate missing R and B values on green pixels, we use the two closest vertical or horizontal neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "id": "iopmCRzY8Vx4",
    "outputId": "c6e6ea2b-2250-4c8e-8ab3-9253faef23f8"
   },
   "outputs": [],
   "source": [
    "def isp_bilinear_demosaicing(img_in) -> np.ndarray:\n",
    "  kernel_G  = np.array([[0, 0.25, 0], [0.25, 1, 0.25], [0, 0.25, 0]])\n",
    "  kernel_RB = np.array([[0.25, 0.5, 0.25], [0.5, 1, 0.5], [0.25, 0.5, 0.25]])\n",
    "  img_out = np.empty_like(img_in)\n",
    "  img_out[:, :, 0] = scipy.ndimage.correlate(img_in[:, :, 0], kernel_RB, mode='mirror')\n",
    "  img_out[:, :, 1] = scipy.ndimage.correlate(img_in[:, :, 1], kernel_G , mode='mirror')\n",
    "  img_out[:, :, 2] = scipy.ndimage.correlate(img_in[:, :, 2], kernel_RB, mode='mirror')\n",
    "  return img_out\n",
    "\n",
    "img_dem_bil = isp_bilinear_demosaicing(img_split)\n",
    "imshow(img_dem_bil[1842:1872, 1778:1820])\n",
    "imshow(img_dem_bil[1502:1532, 1878:1920])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fS2JRPyT2ejk"
   },
   "source": [
    "### <font color='blue'> Question 0\n",
    "Explain how the above code works?\n",
    "\n",
    "\n",
    "The code implements bilinear demosaicing for a single-channel image with a Bayer filter pattern, converting it into a full-color image. It uses predefined interpolation kernels for the red/blue (R/B) and green (G) channels. The code convolves these kernels with the input image using the scipy.ndimage.correlate function, applying mirror boundary conditions to avoid edge artifacts. The result is stored in an output array img_out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXPDv4M8HzVu"
   },
   "source": [
    "## Advanced Demosaicing\n",
    "\n",
    "Finally we attempt to design a more sophisticated demosaicing algorithm.\n",
    "\n",
    "Remember that we're basically just guessing the values we did not observe. The question is, what values are plausible? Writing a demosaicing algorithm means formulating a strategy for finding plausible values, exploiting supposed properties of the photographed scene.\n",
    "\n",
    "Our above linear interpolation strategy supposes that the photographed scene does not contain any \"sudden\" spatial variations. This heuristic is correct for the vast majority of pixels, but wrong for pixels on sharp edges (observe the \"zipper\" artifact).\n",
    "\n",
    "To better restore edges and high frequencies, we introduce two heuristics:\n",
    "- The scene is entirely composed of horizontal and vertical edges. Rather than using all four nearest neighbors for interpolating missing green pixels, we only use the two that follow the direction of the edge.\n",
    "- Spatial variations at the pixel level are identical in all color channels. High frequencies that we observe in the green channel (where the Bayer pattern has twice more pixels) can be transposed in the red and blue channels.\n",
    "\n",
    "Based on these heuristics, we propose the following algorithm:\n",
    "- On each missing green pixel, compute horizontal and vertical linear interplation.\n",
    "- Among the two interpolations, select the one that leads to minimum variation in its direction. This step yields a fully interpolated G channel.\n",
    "- On each pixel where R or B were observed, compute respectively ΔR = R–G and ∆B = B–G.\n",
    "- Compute ∆R and ∆B for pixels where red and blue have not been observed, using linear interpolation.\n",
    "- Obtain fully interpolated R and B channels by adding the fully interpolated ∆R and ∆B to the fully interpolated G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 941
    },
    "id": "PM1s7RpQHgSo",
    "outputId": "5bfba295-568e-4ce9-b2d9-354320579bc4"
   },
   "outputs": [],
   "source": [
    "def isp_advanced_demosaicing(img_in) -> np.ndarray:\n",
    "  img_out = np.empty_like(img_in)\n",
    "  h, w, _ = img_in.shape\n",
    "  # Compute two proposals for G\n",
    "  kernel_dir = np.array([0.5, 1.0, 0.5])\n",
    "  green_H = scipy.ndimage.correlate1d(img_in[:, :, 1], kernel_dir, axis=1, mode='mirror')\n",
    "  green_V = scipy.ndimage.correlate1d(img_in[:, :, 1], kernel_dir, axis=0, mode='mirror')\n",
    "  # Compute variation and select best proposal for G\n",
    "  kernel_var  = np.array([-1, 0, 1])\n",
    "  var_H = np.abs(scipy.ndimage.correlate1d(green_H, kernel_var, axis=1, mode='mirror'))\n",
    "  var_V = np.abs(scipy.ndimage.correlate1d(green_V, kernel_var, axis=0, mode='mirror'))\n",
    "  img_out[:, :, 1] = (var_H > var_V).choose(green_H, green_V)\n",
    "  # Compute deltaR and deltaB\n",
    "  deltaR = np.zeros((h, w))\n",
    "  deltaR[0::2, 0::2] = img_in[0::2, 0::2, 0] - img_out[0::2, 0::2, 1]\n",
    "  deltaB = np.zeros((h, w))\n",
    "  deltaB[1::2, 1::2] = img_in[1::2, 1::2, 2] - img_out[1::2, 1::2, 1]\n",
    "  # Linear interpolation for deltaR and deltaB\n",
    "  kernel_RB = np.array([[0.25, 0.5, 0.25], [0.5, 1, 0.5], [0.25, 0.5, 0.25]])\n",
    "  deltaR = scipy.ndimage.correlate(deltaR, kernel_RB, mode='mirror')\n",
    "  deltaB = scipy.ndimage.correlate(deltaB, kernel_RB, mode='mirror')\n",
    "  # Compute R and B\n",
    "  img_out[:, :, 0] = (img_out[:, :, 1] + deltaR).clip(0, 1)\n",
    "  img_out[:, :, 2] = (img_out[:, :, 1] + deltaB).clip(0, 1)\n",
    "\n",
    "  return img_out\n",
    "\n",
    "img_dem_adv = isp_advanced_demosaicing(img_split)\n",
    "imshow(img_dem_adv[1842:1872, 1778:1820])\n",
    "imshow(img_dem_adv[1502:1532, 1878:1920])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2likwIUtWnqp"
   },
   "source": [
    "# White Balance\n",
    "\n",
    "In this section we will correct the white balance and try the most simple automatic white balance algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4vGEnZAuRCx"
   },
   "source": [
    "Color consistency, also called chromatic adaptation, is the brain's ability to neutralize the spectrum of the ambient light.\n",
    "\n",
    "White balance, which mimicks this physiological aspect, consists in applying gains on Blue and Red channels to neutralize objects that reflect all the spectrum without absorption, also known as objects of gray color.\n",
    "\n",
    "Automatic White Balance (AWB) is the name of the algorithm which tries to guess this blue and red gains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "parflFvPrGwL"
   },
   "source": [
    "## As-Shot White Balance\n",
    "\n",
    "White balance gains resulting from camera AWB algorithm are part of the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BJACOwIugPj",
    "outputId": "c8b104f7-b5be-44e8-ae54-c72c692dc353"
   },
   "outputs": [],
   "source": [
    "# Let's extract the white balance gain from the metadata. We name it White Balance As Shot.\n",
    "wb_as_shot = np.array(raw.camera_whitebalance)[:3]\n",
    "print(f\"White balance gain from camera AWB: {wb_as_shot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Rl3bCvLp3TEg",
    "outputId": "1e179d90-1132-4132-f2c0-329020ca2b9d"
   },
   "outputs": [],
   "source": [
    "# Show the image before and after the white balance.\n",
    "imshow(img_dem_adv[900:1650, 2300:3050])\n",
    "img_wb_as_shot = img_dem_adv * wb_as_shot\n",
    "imshow(img_wb_as_shot[900:1650, 2300:3050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2gYv4qmGcc5"
   },
   "source": [
    "## Auto White Balance\n",
    "\n",
    "Methods that estimate the white balance gain are called auto white balance algorithms, and can be very sophisticated (semantic interpretation of the scene via AI, use of additionnal sensors to observe the spectrum of the ambient light, etc...)\n",
    "\n",
    "A naive classic but surprisingly effective such algorithm is called gray-world white balancing and relies on the gray world assumption, which states that the scene, on average, is gray. The gray-world assumption holds if we have a good distribution of colors in the scene. Assuming that the scene, on average, is gray, the reflected color, on average, is the color of the light source. Therefore, we can estimate the illumination color cast by looking at the average color and comparing it to gray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpqL4CaRAmrg"
   },
   "source": [
    "## <font color='blue'> Exercise 1\n",
    "\n",
    "Estimate the white balance gains using the gray-world assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J6VAgXKDm6sy",
    "outputId": "3a92ee22-b8a6-46d7-e2ea-5fae7a19a354"
   },
   "outputs": [],
   "source": [
    "########################\n",
    "# use the img_dem_adv image and write white balance gain into wb_auto\n",
    "\n",
    "average_color = np.mean(img_dem_adv, axis=(0, 1))\n",
    "\n",
    "wb_auto = 255 / average_color\n",
    "\n",
    "#########################\n",
    "print(f\"White balance gain using the gray-world assumption: {wb_auto}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "NmTGUEWDGb5h",
    "outputId": "06e3fccf-92ac-4be7-8836-3fd24829d0bb"
   },
   "outputs": [],
   "source": [
    "img_wb_auto = img_dem_adv * wb_auto\n",
    "imshow(img_wb_auto[900:1650, 2300:3050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQeBbzvc4TDz"
   },
   "source": [
    "As you can see, the results are rather close. Nevertheless the camera's more sophisticated auto white balance is superior: it correctly neutralizes the white background of the stripe patterns, while it remains a bit blueish using the gray-world assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GmDgabhgXDIg"
   },
   "source": [
    "# Color Rendering\n",
    "\n",
    "In this section we will play on the color rendering by applying a color matrix and adjust the saturation of colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NGpndlcS9wL8"
   },
   "source": [
    "## Color Matrix\n",
    "\n",
    "A color matrix is a 3×3 matrix applied to the vector of (R, G, B).\n",
    "\n",
    "\\begin{matrix}\n",
    "\\begin{bmatrix}\n",
    "    R_{out} \\\\\n",
    "    G_{out} \\\\\n",
    "    B_{out}\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    m_{11} & m_{12} & m_{13} \\\\\n",
    "    m_{21} & m_{22} & m_{23} \\\\\n",
    "    m_{31} & m_{32} & m_{33}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    R_{in} \\\\\n",
    "    G_{in} \\\\\n",
    "    B_{in}\n",
    "\\end{bmatrix}\n",
    "\\end{matrix}\n",
    "\n",
    "The goal of the matrix is to modulate the color rendering. This is a very simple way of altering the colors.\n",
    "More sophisiticated ones are used in modern cameras.\n",
    "\n",
    "Color Matrix can be used to reach fidelity, or saturate more the colors, or give a particular signature to the colors.\n",
    "\n",
    "All the difficulty resides in finding the good matrix.\n",
    "\n",
    "Color Matrix resulting from camera color tuning is part of the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKZ34gq49qQR",
    "outputId": "8427135d-8633-417e-cee4-828c184c62d1"
   },
   "outputs": [],
   "source": [
    "color_matrix = raw.color_matrix[0:3,0:3]\n",
    "print(f\"Color matrix: {color_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWCScElB7d7z"
   },
   "source": [
    "While the matrix has 9 coefficients, by convention it must change neither exposure nor white balance. In other words, gray pixels (where R=G=B) must remain unchanged. This means that the sum of each row must be equal to one. Thus, the matrix has actually only 6 degrees fo freedom.\n",
    "\n",
    "Let's verify this property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Li8k5kV_7Mud",
    "outputId": "011cfcc3-923a-4595-dfd6-6a4acb8416ab"
   },
   "outputs": [],
   "source": [
    "print(f\"Color matrix row sum: {color_matrix.sum(axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1d3X7_eG_0mH"
   },
   "source": [
    "Now let's apply the matrix to the image and look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "JkcjmmIUJ94f",
    "outputId": "141602c1-6cff-4152-e6fd-f8b0d881bc9e"
   },
   "outputs": [],
   "source": [
    "def isp_apply_matrix(img_in, color_matrix) -> np.ndarray:\n",
    "  return np.dot(img_in, color_matrix.T).clip(0, 1)\n",
    "\n",
    "img_cm = isp_apply_matrix(img_wb_as_shot, color_matrix)\n",
    "imshow(img_cm[900:1650, 2300:3050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLEQw8K5PCJC"
   },
   "source": [
    "Observe that the colors are more vivid, more saturated than before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W98kg3AV_-PJ"
   },
   "source": [
    "# Color Artifacts\n",
    "\n",
    "After applying white balance and color matrix, we observe that something is wrong. Look at all these reddish color artifacts on the high frequency stripe patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcAMFqOVBPm6"
   },
   "source": [
    "### <font color='blue'> Exercise 2\n",
    "\n",
    "What is wrong in our processing pipeline? Hint: it's related to one of the assumtions in our demosaicing algorithm.\n",
    "\n",
    "Propose a fix and implement it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3_7FJq3PStt"
   },
   "source": [
    "The issue is related to the assumption that spatial variations at the pixel level are identical in all color channels. This assumption may not hold in all situations, and it can lead to artifacts.\n",
    "\n",
    "To resolve the issue, we can use the Malvar Demosaicing algorithm which separates the interpolation of the green channel from the red and blue channels, handling channel-specific variations better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LxRvVERUBryg",
    "outputId": "3876fff7-24db-4571-819d-a8dc30e9d442"
   },
   "outputs": [],
   "source": [
    "def malvar_demosaicing(img_in) -> np.ndarray:\n",
    "    img_out = np.empty_like(img_in)\n",
    "    h, w, _ = img_in.shape\n",
    "\n",
    "    green_kernel = np.array([[0, 1, 0],\n",
    "                             [1, 4, 1],\n",
    "                             [0, 1, 0]]) / 4.0\n",
    "    img_out[:, :, 1] = scipy.ndimage.correlate(img_in[:, :, 1], green_kernel, mode='reflect')\n",
    "\n",
    "    red_kernel = np.array([[1, 2, 1],\n",
    "                           [2, 4, 2],\n",
    "                           [1, 2, 1]]) / 4.0\n",
    "    blue_kernel = red_kernel\n",
    "\n",
    "    img_out[:, :, 0] = scipy.ndimage.correlate(img_in[:, :, 0], red_kernel, mode='reflect')\n",
    "    img_out[:, :, 2] = scipy.ndimage.correlate(img_in[:, :, 2], blue_kernel, mode='reflect')\n",
    "\n",
    "    return img_out.clip(0, 1)\n",
    "\n",
    "img_cm = isp_apply_matrix(isp_advanced_demosaicing(img_split)* wb_as_shot, color_matrix)\n",
    "imshow(img_cm[900:1650, 2300:3050])\n",
    "img_cm = isp_apply_matrix(isp_advanced_demosaicing(img_split * wb_as_shot), color_matrix)\n",
    "imshow(img_cm[900:1650, 2300:3050])\n",
    "\n",
    "img_cm = isp_apply_matrix(malvar_demosaicing(img_split)* wb_as_shot, color_matrix)\n",
    "imshow(img_cm[900:1650, 2300:3050])\n",
    "img_cm = isp_apply_matrix(malvar_demosaicing(img_split * wb_as_shot), color_matrix)\n",
    "imshow(img_cm[900:1650, 2300:3050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mhm3xctnGJt2"
   },
   "source": [
    "# Gamma Compression\n",
    "\n",
    "Until now our image is still linear, i.e. the graylevels are proportional to the amount of light received by the sensor. However, this is not what screens and operating systems expect. They expect the image to be non-linear, with a so-called gamma compression applied.\n",
    "\n",
    "In order to faithfully reproduce the brightness and contrast of the scene on screen, we must apply such a gamma compression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 879
    },
    "id": "FELcK52TKjJK",
    "outputId": "fefd4c5b-e851-4299-8b5f-1c65272d6a6a"
   },
   "outputs": [],
   "source": [
    "def isp_apply_gamma(img_in) -> np.ndarray:\n",
    "  return img_in ** (1/2.2)\n",
    "\n",
    "img_gamma = isp_apply_gamma(img_cm)\n",
    "\n",
    "imshow(img_cm)\n",
    "imshow(img_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eewPzJxIPww9"
   },
   "source": [
    "# Common Image Enhancements\n",
    "\n",
    "The above image has received all essential processing steps. But probably it will not receive a lot of likes when posted on social networks, because it does not \"pop\". Let's apply some basic image enhancements to make the image more exciting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a1Jch_3pJ94f"
   },
   "source": [
    "## Color Saturation\n",
    "\n",
    "We would like to play with the saturation of colors.\n",
    "\n",
    "Let's first understand what would be an image without colors: this would be an image with the same color on each channel.\n",
    "\n",
    "This corresponds to a matrix of the following form:\n",
    "\n",
    "\\begin{matrix}\n",
    "\\begin{bmatrix}\n",
    "    R_{out} \\\\\n",
    "    G_{out} \\\\\n",
    "    B_{out}\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "    m_{r2gray} & m_{g2gray} & m_{b2gray} \\\\\n",
    "    m_{r2gray} & m_{g2gray} & m_{b2gray} \\\\\n",
    "    m_{r2gray} & m_{g2gray} & m_{b2gray}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "    R_{in} \\\\\n",
    "    G_{in} \\\\\n",
    "    B_{in}\n",
    "\\end{bmatrix}\n",
    "\\end{matrix}\n",
    "\n",
    "We want the lightness of the resulting image to be identical to the original image.\n",
    "A simple way to achieve this is to have the sum of the coefficients of each line to be equal to one.\n",
    "Setting each coefficient to $1/3$ is simple but doesn’t work as well as expected. The reason is that human vision is most sensitive to green light, less sensitive to red light, and the least sensitive to blue light. Therefore, the three colors should have different weights in the distribution.\n",
    "\n",
    "The following weights comes from the analog television standards and are commonly used to convert RGB values to Y (or Luma) gray levels:\n",
    "\n",
    "$Y = 0.299R + 0.587G + 0.114B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "XuIkBvy6A2cj",
    "outputId": "4b09f690-6ff1-4328-971d-92e32befb986"
   },
   "outputs": [],
   "source": [
    "# Convert the image to Gray\n",
    "gray_matrix = np.array([\n",
    "  [0.299, 0.587, 0.114],\n",
    "  [0.299, 0.587, 0.114],\n",
    "  [0.299, 0.587, 0.114]\n",
    "])\n",
    "\n",
    "img_gray = isp_apply_matrix(img_gamma, gray_matrix)\n",
    "\n",
    "imshow(img_gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbUqiRkRJ94g"
   },
   "source": [
    "An intuitive but effective way to play with the saturation of colors is to interpolate/extrapolate between the colorToGray matrix and the Identity Matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8oKry8f9FLwI"
   },
   "source": [
    "### <font color='blue'> Exercise 3\n",
    "\n",
    "Write a function that generates a saturation adjustment matrix according to a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "ADkSMW6uJ94g",
    "outputId": "7b60a102-7413-402d-9061-3418cc70d97b"
   },
   "outputs": [],
   "source": [
    "def make_sat_matrix(sat_param) -> np.ndarray:\n",
    "    color_to_gray = np.array([0.299, 0.587, 0.114])\n",
    "\n",
    "    identity_matrix = np.identity(3)\n",
    "\n",
    "    sat_matrix = (1 - sat_param) * color_to_gray + sat_param * identity_matrix\n",
    "\n",
    "    return sat_matrix\n",
    "\n",
    "\n",
    "sat_matrix = make_sat_matrix(1.5)\n",
    "\n",
    "img_sat = isp_apply_matrix(img_gamma, sat_matrix)\n",
    "\n",
    "imshow(img_sat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6u5RdVOJ94h"
   },
   "source": [
    "## Global Contrast\n",
    "\n",
    "The global contrast in the image, i.e. the respective levels of shadows and highlights, can be adjusted via a transfer function. An S-curve is a simple way to adjust the contrast.\n",
    "\n",
    "It is usually implemented with a Look-Up Table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_r7ENDdkJ94h"
   },
   "outputs": [],
   "source": [
    "def isp_apply_LUT(img_in, LUT) -> np.ndarray:\n",
    "  N = len(LUT)\n",
    "  return LUT[(img_in * N).astype(int).clip(0, N-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoTeKilfJ94h"
   },
   "source": [
    "Let's code a simple S-curve LUT with a sinus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "_LBr_wu4J94h",
    "outputId": "92ef2fc1-23f1-43ec-a1dd-dec9db6c7a7f"
   },
   "outputs": [],
   "source": [
    "N = 1024\n",
    "t = np.linspace(0, 1 - 1/N, N)\n",
    "LUT_sine = (np.sin(t * np.pi - np.pi / 2) + 1) / 2\n",
    "\n",
    "plt.plot(LUT_sine)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "vOfDYXvTJ94i",
    "outputId": "25d10bfe-8d73-41e7-8678-a153048cac91"
   },
   "outputs": [],
   "source": [
    "img_contrast = isp_apply_LUT(img_sat, LUT_sine)\n",
    "\n",
    "imshow(img_contrast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Caimbv2OJ94i"
   },
   "source": [
    "You can observe that the increase in contrast has further increased the color saturation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iI6GbkqPXvQd"
   },
   "source": [
    "## Unsharp Mask\n",
    "\n",
    "In this section we will see a classical method to improve the perceptual sharpness of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLae8mSdJ94i"
   },
   "source": [
    "\n",
    "In photography, acutance describes a subjective perception of sharpness that is related to the edge contrasts in an image. Lenses act naturally as low pass filters and smooth the fine details, or high spatial frequencies, in an image.\n",
    "\n",
    "Various techniques can be used to increase the acutance, or make the image look sharper.\n",
    "\n",
    "Unsharp masking (USM) is an image sharpening technique, first implemented in darkroom photography, but now commonly used in digital image processing software. Its name derives from the fact that the technique uses a blurred, or \"unsharp\", negative image to create a mask of the original image.\n",
    "\n",
    "$sharpened = original + (original − blurred) × amount$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Y79WewxJJ94j",
    "outputId": "54fc1f64-b601-421c-cf91-d65ac9e0dded"
   },
   "outputs": [],
   "source": [
    "def isp_blur(img_in, sigma):\n",
    "  return scipy.ndimage.gaussian_filter(img_in, [sigma, sigma, 0], mode=\"nearest\")\n",
    "\n",
    "img_blur = isp_blur(img_contrast, sigma=3)\n",
    "\n",
    "imshow(img_contrast[900:1650, 2300:3050])\n",
    "imshow(img_blur[900:1650, 2300:3050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yznV5CcBJ94j"
   },
   "source": [
    "### <font color='blue'> Exercise 4\n",
    "\n",
    "Write a function that applies an unsharp mask with a strength parameter as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "id": "ESAILkdyJ94j",
    "outputId": "32f61b80-46a0-4fc2-f67c-a25735aa8837"
   },
   "outputs": [],
   "source": [
    "def isp_usm(img_in, sigma, strength) -> np.ndarray:\n",
    "    img_blurred = scipy.ndimage.gaussian_filter(img_in, sigma)\n",
    "\n",
    "    img_mask = img_in - img_blurred\n",
    "\n",
    "    img_sharp = img_in + strength * img_mask\n",
    "\n",
    "    img_sharp = np.clip(img_sharp, 0, 255)\n",
    "\n",
    "    return img_sharp\n",
    "\n",
    "img_sharp = isp_usm(img_contrast, sigma=3, strength=0.5)\n",
    "\n",
    "imshow(img_sharp[900:1650, 2300:3050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbZL7LbyzTbI"
   },
   "source": [
    "Now our image is ready to receive some oohs and aahs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9uVqH2TOidS"
   },
   "source": [
    "# Philosophical End Note\n",
    "\n",
    "At the beginning of this course we introduced two assumptions about the world and stated that they are true in most cases:\n",
    "- The image contains no sudden spatial variations (thus we can use bilinear interpolation for demosaicing).\n",
    "- The world is gray (thus we can use the average of each channel to compute the white balance scales).\n",
    "\n",
    "Then, in order to make the image more \"interesting\" for the human eye:\n",
    "- We emphasized sudden spatial variations (sharpening).\n",
    "- We made the image less gray (more colorful via saturation, more distinct black or white via contrast).\n",
    "\n",
    "Are these two in contradiction? Not at all. According to Claude Shannon's information theory, \"the less probable an event is, the more surprising it is and the more information it yields.\" From an evolutionary point of view it makes totally sense that our visual system pays more attention to images that violate assumptions that are commonly true.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Y-JQO502qdCb",
    "umXJ3YjviYk7",
    "SsxrYNg933Np",
    "1rmjPk4UYgvf",
    "ZrF3GnO-VbLc",
    "eX1JHNiElnfr",
    "PXPDv4M8HzVu",
    "2likwIUtWnqp",
    "LpqL4CaRAmrg",
    "GmDgabhgXDIg",
    "W98kg3AV_-PJ",
    "lcAMFqOVBPm6",
    "Mhm3xctnGJt2",
    "eewPzJxIPww9",
    "8oKry8f9FLwI"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "01733018d8c9657de1e1b8d6ed5f204813fbdb61ffcb372a101bd8f1b1d046b6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
